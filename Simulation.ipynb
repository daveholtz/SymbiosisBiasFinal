{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996af403-8a8d-4c3d-b72b-552587fafb81",
   "metadata": {
    "id": "996af403-8a8d-4c3d-b72b-552587fafb81",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 1: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd556061-cd7d-469d-8f64-acc223171c82",
   "metadata": {
    "id": "dd556061-cd7d-469d-8f64-acc223171c82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e4bfe-00e7-438c-bf05-9b2194ca2edf",
   "metadata": {
    "id": "0c7e4bfe-00e7-438c-bf05-9b2194ca2edf",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 2: Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a63bc-755b-4b19-b5fb-367acb9e3f0b",
   "metadata": {
    "id": "2b4a63bc-755b-4b19-b5fb-367acb9e3f0b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functions.fn_set_env import Param\n",
    "from functions.fn_set_value import *\n",
    "from functions.fn_algorithm import *\n",
    "from functions.fn_consumption import *\n",
    "from functions.fn_metrics import *\n",
    "from functions.fn_simulation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c783c7b-4dcb-4fa0-b33d-9c96b174e6d6",
   "metadata": {
    "id": "2c783c7b-4dcb-4fa0-b33d-9c96b174e6d6",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 3: Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1b413-4ec5-4ed9-9144-81c0ffce3aaa",
   "metadata": {
    "id": "9ce1b413-4ec5-4ed9-9144-81c0ffce3aaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_simulation_ref(params, user_item_utility, reserve_utilities, algo_1, algo_2):\n",
    "    \"\"\"\n",
    "    Reference Method: \n",
    "    algo_1 and algo_2 for this method are identical recommendation algorithms.\n",
    "    Both algorithms learn from the entirety of the user data, ensuring no differences in how they learn or perform.\n",
    "    This serves as the control group for analyzing potential biases, as no bias is introduced by the learning process.\n",
    "\n",
    "    Args:\n",
    "        params: Contains the enviroment set up.\n",
    "        user_item_utility (function/array): A utility function or matrix providing user-utility values for items.\n",
    "        reserve_utilities (array): Reserve_utilities for users.\n",
    "        algo_1 (callable): The first recommendation algorithm; signature should match how it's called below.\n",
    "        algo_2 (callable): The second recommendation algorithm; signature should match how it's called below.\n",
    "\n",
    "    Returns:\n",
    "        avg_c_algo_1 (np.array): [mean, 2.5% quantile, 97.5% quantile, variance] of take-up rates for algo_1.\n",
    "        avg_c_algo_2 (np.array): Same structure as avg_c_algo_1 but for algo_2.\n",
    "        avg_TE (np.array): Treatment effect (algo_1 - algo_2) summary stats.\n",
    "        avg_pct_TE (np.array): Percentage-based treatment effect ((algo_1 - algo_2)/algo_1) summary stats.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize results lists\n",
    "    avg_c_algo_1_list = []\n",
    "    avg_c_algo_2_list = []\n",
    "\n",
    "    # Pre-generate user assignment matrix for all simulation rounds (num of rounds = params.B)\n",
    "    # Each row in user_assignments_matrix is a array of length num_users indicating which users are assigned to algo_2 (1) or algo_1 (0).\n",
    "    user_assignments_matrix = np.random.randint(0, 2, (params.B, params.num_users)).astype(bool)\n",
    "\n",
    "    # Number of new items in each period\n",
    "    n_new = params.num_items_per_period\n",
    "\n",
    "    # For each round of simulation\n",
    "    for b in range(params.B):\n",
    "        # Get user assignments for this simulation round\n",
    "        user_assignments = user_assignments_matrix[b]\n",
    "        \n",
    "        # Generate random noise for each period and user\n",
    "        # Shape: (num_periods x num_users x (num_periods * num_items_per_period))\n",
    "        noise = np.random.normal(0, 1,(params.num_periods, params.num_users, params.num_periods * params.num_items_per_period))\n",
    "        \n",
    "        # Initialize the user-item interaction matrix: 0 indicates no consumption, 1 indicates consumption\n",
    "        # It’s essentially the interaction history that the algorithms use to learn user preferences.\n",
    "        # Shape: (num_users x num_items)\n",
    "        interaction_matrix = np.zeros((params.num_users, params.num_items))\n",
    "\n",
    "        # Record previous consumption to keep track of all items consumed by each user after the initial period\n",
    "        # Used later to calculate take up rate\n",
    "        prev_consumed_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "        for t in range(params.num_periods):\n",
    "\n",
    "            #### Introduce new goods\n",
    "            # list(range(t * n_new, (t + 1) * n_new)) generates a list of new item indices introduced at period t. \n",
    "            # For example, if n_new = 5 and t = 2, this would produce [10, 11, 12, 13, 14].\n",
    "            # np.repeat(..., params.num_users, axis=0) replicates this list so that each user has the same set of new items to choose from initially.\n",
    "            new_items = np.repeat([list(range(t * n_new, (t + 1) * n_new))], params.num_users, axis=0)\n",
    "            \n",
    "            # np.apply_along_axis(np.random.shuffle, 1, new_items) shuffles the order of these new item indices independently for each user.\n",
    "            np.apply_along_axis(np.random.shuffle, 1, new_items)\n",
    "            \n",
    "            # Initialize recommended items list for each user\n",
    "            recommended_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "            #### Recommendation step (happens only after initial periods)\n",
    "            # Update the training data every training_frequency periods:\n",
    "            if t % params.training_frequency == 0 and t >= params.initial_periods:\n",
    "                # Use item interation data for each user up to the current period (t * n_new) as training data\n",
    "                # :(t * n_new) reflects all the items introduced up to the start of period t\n",
    "                training_data = interaction_matrix[:, :(t * n_new)]\n",
    "                \n",
    "                # Recommended_items: Matrix of ranked item IDs recommended to each user.\n",
    "                recommended_items_1 = algo_1(training_data, noise[t,:, :(t * n_new)])\n",
    "                recommended_items_2 = algo_2(training_data, noise[t,:, :(t * n_new)])\n",
    "\n",
    "                # Merge the two algorithms' recommendation list\n",
    "                recommended_items = recommended_items_1.copy()\n",
    "                recommended_items[user_assignments] = recommended_items_2[user_assignments]\n",
    "\n",
    "            #### Consumption step\n",
    "            # Simulate user consumption\n",
    "            # chosen_items reflects ID of the item each user chooses to consume, \n",
    "            # where -1 indicates that user does not consume any item\n",
    "            if t <  params.initial_periods:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "            else:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "\n",
    "            # Update the user-item interaction in interaction_matrix and prev_consumed_items\n",
    "            for user_id, chosen_item in enumerate(chosen_items):\n",
    "                prev_consumed_items[user_id].append(chosen_item)\n",
    "                if chosen_item != -1:\n",
    "                    interaction_matrix[user_id,chosen_item] = 1\n",
    "                    \n",
    "        # Calculate the average take-up rate\n",
    "        [avg_c_algo_1,avg_c_algo_2] = avg_take_up_rate_by_period(prev_consumed_items, user_assignments, params)\n",
    "        avg_c_algo_1_list.append(np.mean(avg_c_algo_1[params.initial_periods:]))\n",
    "        avg_c_algo_2_list.append(np.mean(avg_c_algo_2[params.initial_periods:]))\n",
    "        \n",
    "        if b < params.B:\n",
    "            # Print the count of the simulation with replacement\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\", end='\\r', flush=True)\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "        else:\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\")\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "\n",
    "    # Calculate the average take up rate for algo_1 and algo_2 across simulations\n",
    "    avg_c_algo_1 = np.zeros(4)\n",
    "    avg_c_algo_1[0] = np.mean(avg_c_algo_1_list, axis=0)\n",
    "    avg_c_algo_1[1] = np.quantile(avg_c_algo_1_list,0.025)\n",
    "    avg_c_algo_1[2] = np.quantile(avg_c_algo_1_list,0.975)\n",
    "    avg_c_algo_1[3] = np.var(avg_c_algo_1, axis=0)\n",
    "\n",
    "    avg_c_algo_2 = np.zeros(4)\n",
    "    avg_c_algo_2[0] = np.mean(avg_c_algo_2_list, axis=0)\n",
    "    avg_c_algo_2[1] = np.quantile(avg_c_algo_2_list,0.025)\n",
    "    avg_c_algo_2[2] = np.quantile(avg_c_algo_2_list,0.975)\n",
    "    avg_c_algo_2[3] = np.var(avg_c_algo_2, axis=0)\n",
    "    \n",
    "    # Calculate the average Treatment effect (algo_1 - algo_2) across simulations\n",
    "    avg_TE_list = np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list)\n",
    "    avg_TE = np.zeros(4)\n",
    "    avg_TE[0] = np.mean(avg_TE_list, axis=0)\n",
    "    avg_TE[1] = np.quantile(avg_TE_list,0.025)\n",
    "    avg_TE[2] = np.quantile(avg_TE_list,0.975)\n",
    "    avg_TE[3] = np.var(avg_TE_list, axis=0)\n",
    "    \n",
    "    # Calculate the average percentage Treatment effect across simulations\n",
    "    avg_pct_TE_list = (np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list))/np.array(avg_c_algo_1_list)\n",
    "    avg_pct_TE = np.zeros(4)\n",
    "    avg_pct_TE[0] = np.mean(avg_pct_TE_list, axis=0)\n",
    "    avg_pct_TE[1] = np.quantile(avg_pct_TE_list,0.025)\n",
    "    avg_pct_TE[2] = np.quantile(avg_pct_TE_list,0.975)\n",
    "    avg_pct_TE[3] = np.var(avg_pct_TE_list, axis=0)\n",
    "    \n",
    "    return avg_c_algo_1, avg_c_algo_2, avg_TE, avg_pct_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2087b8-a1cd-4fb5-b1ce-3ebd7f68ea55",
   "metadata": {
    "id": "8b2087b8-a1cd-4fb5-b1ce-3ebd7f68ea55",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 4: Naive experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eddea2-86ca-433f-9b28-5dcd511626f8",
   "metadata": {
    "id": "b8eddea2-86ca-433f-9b28-5dcd511626f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_simulation_naive(params, user_item_utility, reserve_utilities, algo_1, algo_2, treatment_percentage):\n",
    "    \"\"\"\n",
    "    Naive Method: \n",
    "    Both algo_1 and algo_2 learn from the same user data.\n",
    "    All users interact with the same pool of items.\n",
    "    \n",
    "    Args:\n",
    "        params: Contains the enviroment set up.\n",
    "        user_item_utility (function/array): A utility function or matrix providing user-utility values for items.\n",
    "        reserve_utilities (array): Reserve_utilities for users.\n",
    "        algo_1 (callable): The first recommendation algorithm; signature should match how it's called below.\n",
    "        algo_2 (callable): The second recommendation algorithm; signature should match how it's called below.\n",
    "        treatment_percentage (float): Percentage of treated user\n",
    "\n",
    "    Returns:\n",
    "        avg_c_algo_1 (np.array): [mean, 2.5% quantile, 97.5% quantile, variance] of take-up rates for algo_1.\n",
    "        avg_c_algo_2 (np.array): Same structure as avg_c_algo_1 but for algo_2.\n",
    "        avg_TE (np.array): Treatment effect (algo_1 - algo_2) summary stats.\n",
    "        avg_pct_TE (np.array): Percentage-based treatment effect ((algo_1 - algo_2)/algo_1) summary stats.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize results lists\n",
    "    avg_c_algo_1_list = []\n",
    "    avg_c_algo_2_list = []\n",
    "\n",
    "    # Pre-generate user assignment matrix for all simulation rounds (num of rounds = params.B)\n",
    "    # Each row in user_assignments_matrix is a array of length num_users indicating which users are assigned to algo_2 (1) or algo_1 (0).\n",
    "    user_assignments_matrix = np.random.choice(\n",
    "            [0, 1], size=(params.B, params.num_users), p=[1-treatment_percentage, treatment_percentage]\n",
    "        ).astype(bool)    \n",
    "    \n",
    "\n",
    "    # Number of new items in each period\n",
    "    n_new = params.num_items_per_period\n",
    "\n",
    "    # For each round of simulation\n",
    "    for b in range(params.B):\n",
    "        # Get user assignments for this simulation round\n",
    "        user_assignments = user_assignments_matrix[b]\n",
    "\n",
    "    \n",
    "        # Generate random noise for each period and user\n",
    "        # Shape: (num_periods x num_users x (num_periods * num_items_per_period))\n",
    "        noise = np.random.normal(0, 1,(params.num_periods,params.num_users, params.num_periods * params.num_items_per_period))\n",
    "        \n",
    "        # Initialize the user-item interaction matrix: 0 indicates no consumption, 1 indicates consumption\n",
    "        # It’s essentially the interaction history that the algorithms use to learn user preferences.\n",
    "        # Shape: (num_users x num_items)\n",
    "        interaction_matrix = np.zeros((params.num_users, params.num_items))\n",
    "\n",
    "        # Record previous consumption to keep track of all items consumed by each user after the initial period\n",
    "        # Used later to calculate take up rate\n",
    "        prev_consumed_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "        for t in range(params.num_periods):\n",
    "\n",
    "            #### Introduce new goods\n",
    "            # list(range(t * n_new, (t + 1) * n_new)) generates a list of new item indices introduced at period t. \n",
    "            # For example, if n_new = 5 and t = 2, this would produce [10, 11, 12, 13, 14].\n",
    "            # np.repeat(..., params.num_users, axis=0) replicates this list so that each user has the same set of new items to choose from initially.\n",
    "            new_items = np.repeat([list(range(t * n_new, (t + 1) * n_new))], params.num_users, axis=0)\n",
    "            \n",
    "            # np.apply_along_axis(np.random.shuffle, 1, new_items) shuffles the order of these new item indices independently for each user.\n",
    "            np.apply_along_axis(np.random.shuffle, 1, new_items)\n",
    "            \n",
    "            # Initialize recommended items list for each user\n",
    "            recommended_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "            #### Recommendation step (happens only after initial periods)\n",
    "            # Update the training data every training_frequency periods:\n",
    "            if t % params.training_frequency == 0 and t >= params.initial_periods:\n",
    "                # Use item interation data for each user up to the current period (t * n_new) as training data\n",
    "                # :(t * n_new) reflects all the items introduced up to the start of period t\n",
    "                training_data = interaction_matrix[:, :(t * n_new)]\n",
    "                \n",
    "                # Recommended_items: Matrix of ranked item IDs recommended to each user.\n",
    "                recommended_items_1 = algo_1(training_data, noise[t,:, :(t * n_new)])\n",
    "                recommended_items_2 = algo_2(training_data, noise[t,:, :(t * n_new)])\n",
    "\n",
    "                # Merge the two algorithms' recommendation list\n",
    "                recommended_items = recommended_items_1.copy()\n",
    "                recommended_items[user_assignments] = recommended_items_2[user_assignments]\n",
    "\n",
    "            #### Consumption step\n",
    "            # Simulate user consumption\n",
    "            # chosen_items reflects ID of the item each user chooses to consume, \n",
    "            # where -1 indicates that user does not consume any item\n",
    "            if t <  params.initial_periods:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "            else:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "\n",
    "            # Update the user-item interaction in interaction_matrix and prev_consumed_items\n",
    "            for user_id, chosen_item in enumerate(chosen_items):\n",
    "                prev_consumed_items[user_id].append(chosen_item)\n",
    "                if chosen_item != -1:\n",
    "                    interaction_matrix[user_id,chosen_item] = 1\n",
    "                    \n",
    "        # Calculate the average take-up rate\n",
    "        [avg_c_algo_1,avg_c_algo_2] = avg_take_up_rate_by_period(prev_consumed_items, user_assignments, params)\n",
    "        avg_c_algo_1_list.append(np.mean(avg_c_algo_1[params.initial_periods:]))\n",
    "        avg_c_algo_2_list.append(np.mean(avg_c_algo_2[params.initial_periods:]))\n",
    "        \n",
    "        if b < params.B:\n",
    "            # Print the count of the simulation with replacement\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\", end='\\r', flush=True)\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "        else:\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\")\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "\n",
    "    # Calculate the average take up rate for algo_1 and algo_2 across simulations\n",
    "    avg_algo_1 = np.zeros(4)\n",
    "    avg_algo_1[0] = np.mean(avg_c_algo_1_list, axis=0)\n",
    "    avg_algo_1[1] = np.quantile(avg_c_algo_1_list,0.025)\n",
    "    avg_algo_1[2] = np.quantile(avg_c_algo_1_list,0.975)\n",
    "    avg_algo_1[3] = np.var(avg_algo_1, axis=0)\n",
    "    \n",
    "    avg_algo_2 = np.zeros(4)\n",
    "    avg_algo_2[0] = np.mean(avg_c_algo_2_list, axis=0)\n",
    "    avg_algo_2[1] = np.quantile(avg_c_algo_2_list,0.025)\n",
    "    avg_algo_2[2] = np.quantile(avg_c_algo_2_list,0.975)\n",
    "    avg_algo_2[3] = np.var(avg_algo_2, axis=0)\n",
    "    \n",
    "    # Calculate the average Treatment effect (algo_1 - algo_2) across simulations\n",
    "    avg_TE_list = np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list)\n",
    "    avg_TE = np.zeros(4)\n",
    "    avg_TE[0] = np.mean(avg_TE_list, axis=0)\n",
    "    avg_TE[1] = np.quantile(avg_TE_list,0.025)\n",
    "    avg_TE[2] = np.quantile(avg_TE_list,0.975)\n",
    "    avg_TE[3] = np.var(avg_TE_list, axis=0)\n",
    "    \n",
    "    # Calculate the average percentage Treatment effect across simulations\n",
    "    avg_pct_TE_list = (np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list))/np.array(avg_c_algo_1_list)\n",
    "    avg_pct_TE = np.zeros(4)\n",
    "    avg_pct_TE[0] = np.mean(avg_pct_TE_list, axis=0)\n",
    "    avg_pct_TE[1] = np.quantile(avg_pct_TE_list,0.025)\n",
    "    avg_pct_TE[2] = np.quantile(avg_pct_TE_list,0.975)\n",
    "    avg_pct_TE[3] = np.var(avg_pct_TE_list, axis=0)\n",
    "    \n",
    "    return treatment_percentage, avg_algo_1, avg_algo_2, avg_TE, avg_pct_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e4b29-f863-49a7-90a8-e8d1e62da183",
   "metadata": {
    "id": "052e4b29-f863-49a7-90a8-e8d1e62da183",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 5: Data-diverted experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd05690-6e54-4a49-9d2b-d4ae0398fcbf",
   "metadata": {
    "id": "6bd05690-6e54-4a49-9d2b-d4ae0398fcbf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_simulation_data_diverted(params, user_item_utility, reserve_utilities, algo_1, algo_2, treatment_percentage):\n",
    "    \"\"\"\n",
    "    Data-diverted Method: \n",
    "    Algo_1 and algo_2 each keeps a separate interaction history for their own users, and learns from their own interaction history. \n",
    "    Users interact with the same pool of items.\n",
    "    \n",
    "    Args:\n",
    "        params: Contains the enviroment set up.\n",
    "        user_item_utility (function/array): A utility function or matrix providing user-utility values for items.\n",
    "        reserve_utilities (array): Reserve_utilities for users.\n",
    "        algo_1 (callable): The first recommendation algorithm; signature should match how it's called below.\n",
    "        algo_2 (callable): The second recommendation algorithm; signature should match how it's called below.\n",
    "        treatment_percentage (float): Percentage of treated user\n",
    "\n",
    "    Returns:\n",
    "        avg_c_algo_1 (np.array): [mean, 2.5% quantile, 97.5% quantile, variance] of take-up rates for algo_1.\n",
    "        avg_c_algo_2 (np.array): Same structure as avg_c_algo_1 but for algo_2.\n",
    "        avg_TE (np.array): Treatment effect (algo_1 - algo_2) summary stats.\n",
    "        avg_pct_TE (np.array): Percentage-based treatment effect ((algo_1 - algo_2)/algo_1) summary stats.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize results lists\n",
    "    avg_c_algo_1_list = []\n",
    "    avg_c_algo_2_list = []\n",
    "\n",
    "    # Pre-generate user assignment matrix for all simulation rounds (num of rounds = params.B)\n",
    "    # Each row in user_assignments_matrix is a array of length num_users indicating which users are assigned to algo_2 (1) or algo_1 (0).\n",
    "    user_assignments_matrix = np.random.choice(\n",
    "        [0, 1], size=(params.B, params.num_users), p=[1-treatment_percentage, treatment_percentage]\n",
    "    ).astype(bool)\n",
    "\n",
    "    \n",
    "\n",
    "    # Number of new items in each period\n",
    "    n_new = params.num_items_per_period\n",
    "\n",
    "    # For each round of simulation\n",
    "    for b in range(params.B):\n",
    "        # Get user assignments for this simulation round\n",
    "        user_assignments = user_assignments_matrix[b]\n",
    "        \n",
    "        # Generate random noise for each period and user\n",
    "        # Shape: (num_periods x num_users x (num_periods * num_items_per_period))\n",
    "        noise = np.random.normal(0, 1,(params.num_periods,params.num_users, params.num_periods * params.num_items_per_period))\n",
    "\n",
    "        # Generate user-item interaction matrix for each algorithm : 0 indicates no consumption, 1 indicates consumption\n",
    "        # It’s essentially the interaction history that the algorithms use to learn user preferences.\n",
    "        # Shape: (num_users x num_items)\n",
    "        interaction_matrix_algo_1 = np.zeros((params.num_users, params.num_items))\n",
    "        interaction_matrix_algo_2 = np.zeros((params.num_users, params.num_items))\n",
    "\n",
    "        # Record previous consumption to keep track of all items consumed by each user after the initial period\n",
    "        # Used later to calculate take up rate\n",
    "        prev_consumed_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "        for t in range(params.num_periods):\n",
    "\n",
    "\n",
    "            #### Introduce new goods\n",
    "            # list(range(t * n_new, (t + 1) * n_new)) generates a list of new item indices introduced at period t. \n",
    "            # For example, if n_new = 5 and t = 2, this would produce [10, 11, 12, 13, 14].\n",
    "            # np.repeat(..., params.num_users, axis=0) replicates this list so that each user has the same set of new items to choose from initially.\n",
    "            new_items = np.repeat([list(range(t * n_new, (t + 1) * n_new))], params.num_users, axis=0)\n",
    "            \n",
    "            # np.apply_along_axis(np.random.shuffle, 1, new_items) shuffles the order of these new item indices independently for each user.\n",
    "            np.apply_along_axis(np.random.shuffle, 1, new_items)\n",
    "            \n",
    "            # Initialize recommended items list for each user\n",
    "            recommended_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "            #### Recommendation step (happens only after initial periods)\n",
    "            # Update the training data every training_frequency periods:\n",
    "            if t % params.training_frequency == 0 and t >= params.initial_periods:\n",
    "                # Use item interation data for each user up to the current period (t * n_new) as training data\n",
    "                # :(t * n_new) reflects all the items introduced up to the start of period t\n",
    "                training_data_1 = interaction_matrix_algo_1[:, :(t * n_new)].copy()\n",
    "                training_data_2 = interaction_matrix_algo_2[:, :(t * n_new)].copy()\n",
    "\n",
    "                # Recommended_items: Matrix of ranked item IDs recommended to each user.\n",
    "                recommended_items_1 = algo_1(training_data_1, noise[t,:, :(t * n_new)])\n",
    "                recommended_items_2 = algo_2(training_data_2, noise[t,:, :(t * n_new)])\n",
    "\n",
    "                # Merge the two algorithms' recommendation list\n",
    "                recommended_items = recommended_items_1.copy()\n",
    "                recommended_items[user_assignments] = recommended_items_2[user_assignments]\n",
    "\n",
    "            #### Consumption step\n",
    "            # Simulate user consumption\n",
    "            # chosen_items reflects ID of the item each user chooses to consume, \n",
    "            # where -1 indicates that user does not consume any item\n",
    "            if t <  params.initial_periods:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "            else:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "\n",
    "            # Update the user-item interaction in interaction_matrix and prev_consumed_items\n",
    "            for user_id, chosen_item in enumerate(chosen_items):\n",
    "                prev_consumed_items[user_id].append(chosen_item)\n",
    "                if chosen_item != -1:\n",
    "                    if user_assignments[user_id] == 0:\n",
    "                            interaction_matrix_algo_1[user_id,chosen_item] = 1\n",
    "                    else:\n",
    "                            interaction_matrix_algo_2[user_id,chosen_item] = 1\n",
    "\n",
    "        # Calculate the average take-up rate\n",
    "        [avg_c_algo_1,avg_c_algo_2] = avg_take_up_rate_by_period(prev_consumed_items, user_assignments, params)\n",
    "        avg_c_algo_1_list.append(np.mean(avg_c_algo_1[params.initial_periods:]))\n",
    "        avg_c_algo_2_list.append(np.mean(avg_c_algo_2[params.initial_periods:]))\n",
    "        if b < params.B:\n",
    "            # Print the count of the simulation with replacement\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\", end='\\r', flush=True)\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "        else:\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\")\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "\n",
    "    # Calculate the average take up rate for algo_1 and algo_2 across simulations\n",
    "    avg_algo_1 = np.zeros(4)\n",
    "    avg_algo_1[0] = np.mean(avg_c_algo_1_list, axis=0)\n",
    "    avg_algo_1[1] = np.quantile(avg_c_algo_1_list,0.025)\n",
    "    avg_algo_1[2] = np.quantile(avg_c_algo_1_list,0.975)\n",
    "    avg_algo_1[3] = np.var(avg_algo_1, axis=0)\n",
    "    \n",
    "    avg_algo_2 = np.zeros(4)\n",
    "    avg_algo_2[0] = np.mean(avg_c_algo_2_list, axis=0)\n",
    "    avg_algo_2[1] = np.quantile(avg_c_algo_2_list,0.025)\n",
    "    avg_algo_2[2] = np.quantile(avg_c_algo_2_list,0.975)\n",
    "    avg_algo_2[3] = np.var(avg_c_algo_2_list, axis=0)\n",
    "    \n",
    "    # Calculate the average Treatment effect (algo_1 - algo_2) across simulations\n",
    "    avg_TE_list = np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list)\n",
    "    avg_TE = np.zeros(4)\n",
    "    avg_TE[0] = np.mean(avg_TE_list, axis=0)\n",
    "    avg_TE[1] = np.quantile(avg_TE_list,0.025)\n",
    "    avg_TE[2] = np.quantile(avg_TE_list,0.975)\n",
    "    avg_TE[3] = np.var(avg_TE_list, axis=0)\n",
    "    \n",
    "    # Calculate the average percentage Treatment effect across simulations\n",
    "    avg_pct_TE_list = (np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list))/np.array(avg_c_algo_1_list)\n",
    "    avg_pct_TE = np.zeros(4)\n",
    "    avg_pct_TE[0] = np.mean(avg_pct_TE_list, axis=0)\n",
    "    avg_pct_TE[1] = np.quantile(avg_pct_TE_list,0.025)\n",
    "    avg_pct_TE[2] = np.quantile(avg_pct_TE_list,0.975)\n",
    "    avg_pct_TE[3] = np.var(avg_pct_TE_list, axis=0)\n",
    "\n",
    "\n",
    "    return treatment_percentage, avg_algo_1, avg_algo_2, avg_TE, avg_pct_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4a40d",
   "metadata": {},
   "source": [
    "#### Block 6: User-Corpus Co-diverted experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_user_corpus_codiverted(params, user_item_utility, reserve_utilities,algo_1, algo_2, treatment_percentage):\n",
    "    \"\"\"\n",
    "    User-corpus Co-diverted Method: \n",
    "    Both algo_1 and algo_2 learn from and act on the same user data.\n",
    "    Algo_1 users and algo_2 users interact with their own pool of items, completely separated from each other.\n",
    "    \n",
    "    Args:\n",
    "        params: Contains the enviroment set up.\n",
    "        user_item_utility (function/array): A utility function or matrix providing user-utility values for items.\n",
    "        reserve_utilities (array): Reserve_utilities for users.\n",
    "        algo_1 (callable): The first recommendation algorithm; signature should match how it's called below.\n",
    "        algo_2 (callable): The second recommendation algorithm; signature should match how it's called below.\n",
    "        treatment_percentage (float): Percentage of treated user\n",
    "\n",
    "    Returns:\n",
    "        avg_c_algo_1 (np.array): [mean, 2.5% quantile, 97.5% quantile, variance] of take-up rates for algo_1.\n",
    "        avg_c_algo_2 (np.array): Same structure as avg_c_algo_1 but for algo_2.\n",
    "        avg_TE (np.array): Treatment effect (algo_1 - algo_2) summary stats.\n",
    "        avg_pct_TE (np.array): Percentage-based treatment effect ((algo_1 - algo_2)/algo_1) summary stats.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize results lists\n",
    "    avg_c_algo_1_list = []\n",
    "    avg_c_algo_2_list = []\n",
    "\n",
    "    # Pre-generate user assignment matrix for all simulation rounds (num of rounds = params.B)\n",
    "    # Each row in user_assignments_matrix is a array of length num_users indicating which users are assigned to algo_2 (1) or algo_1 (0).\n",
    "    user_assignments_matrix = np.random.choice(\n",
    "            [0, 1], size=(params.B, params.num_users), p=[1-treatment_percentage, treatment_percentage]\n",
    "        ).astype(bool)\n",
    "\n",
    "    # Pre-generate item assignment matrix for all simulation rounds (num of rounds = params.B)\n",
    "    # Each row in item_assignments_matrix is a array of length num_items indicating which users are assigned to algo_2 (1) or algo_1 (0).\n",
    "    item_assignments_matrix = np.random.choice(\n",
    "            [0, 1], size=(params.B, params.num_items), p=[1-treatment_percentage, treatment_percentage]\n",
    "        ).astype(bool)\n",
    "\n",
    "\n",
    "    # Number of new items in each period\n",
    "    n_new = params.num_items_per_period\n",
    "\n",
    "    # For each round of simulation\n",
    "    for b in range(params.B):\n",
    "        # Get user assignments for this simulation round\n",
    "        user_assignments = user_assignments_matrix[b]\n",
    "        # Get item assignments for this simulation round\n",
    "        item_assignments = item_assignments_matrix[b]\n",
    "\n",
    "        # Generate random noise for each period and user\n",
    "        # Shape: (num_periods x num_users x (num_periods * num_items_per_period))\n",
    "        noise = np.random.normal(0, 1,(params.num_periods,params.num_users, params.num_periods * params.num_items_per_period))\n",
    "        \n",
    "        # Initialize the user-item interaction matrix: 0 indicates no consumption, 1 indicates consumption\n",
    "        # It’s essentially the interaction history that the algorithms use to learn user preferences.\n",
    "        # Shape: (num_users x num_items)\n",
    "        interaction_matrix = np.zeros((params.num_users, params.num_items))\n",
    "\n",
    "        # Record previous consumption to keep track of all items consumed by each user after the initial period\n",
    "        # Used later to calculate take up rate\n",
    "        prev_consumed_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "        for t in range(params.num_periods):\n",
    "\n",
    "            #### Introduce new goods\n",
    "            # list(range(t * n_new, (t + 1) * n_new)) generates a list of new item indices introduced at period t. \n",
    "            # For example, if n_new = 5 and t = 2, this would produce [10, 11, 12, 13, 14].\n",
    "            # np.repeat(..., params.num_users, axis=0) replicates this list so that each user has the same set of new items to choose from initially.\n",
    "            new_items = np.repeat([list(range(t * n_new, (t + 1) * n_new))], params.num_users, axis=0)\n",
    "            \n",
    "            # np.apply_along_axis(np.random.shuffle, 1, new_items) shuffles the order of these new item indices independently for each user.\n",
    "            np.apply_along_axis(np.random.shuffle, 1, new_items)\n",
    "            \n",
    "            # Initialize recommended items list for each user\n",
    "            recommended_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "            #### Recommendation step (happens only after initial periods)\n",
    "            # Update the training data every training_frequency periods:\n",
    "            if t % params.training_frequency == 0 and t >= params.initial_periods:\n",
    "                # Use item interation data for each user up to the current period (t * n_new) as training data\n",
    "                # :(t * n_new) reflects all the items introduced up to the start of period t\n",
    "                training_data = interaction_matrix[:, :(t * n_new)]\n",
    "                \n",
    "                # Recommended_items: Matrix of ranked item IDs recommended to each user.\n",
    "                recommended_items_1 = algo_1(training_data, noise[t,:, :(t * n_new)])\n",
    "                recommended_items_2 = algo_2(training_data, noise[t,:, :(t * n_new)])             \n",
    "                \n",
    "                # Merge the two algorithms' recommendation list\n",
    "                recommended_items = recommended_items_1.copy()\n",
    "                recommended_items[user_assignments] = recommended_items_2[user_assignments]\n",
    "\n",
    "            #### Consumption step\n",
    "            # Simulate user consumption\n",
    "            # chosen_items reflects ID of the item each user chooses to consume, \n",
    "            # where -1 indicates that user does not consume any item\n",
    "            if t <  params.initial_periods:\n",
    "                chosen_items = consume_item_all_users_loop_user_corpus(recommended_items, new_items, user_item_utility, reserve_utilities, params, item_assignments, user_assignments)\n",
    "            else:\n",
    "                chosen_items = consume_item_all_users_loop_user_corpus(recommended_items, new_items, user_item_utility, reserve_utilities, params, item_assignments, user_assignments)\n",
    "\n",
    "            # Update the user-item interaction in interaction_matrix and prev_consumed_items\n",
    "            for user_id, chosen_item in enumerate(chosen_items):\n",
    "                prev_consumed_items[user_id].append(chosen_item)\n",
    "                if chosen_item != -1:\n",
    "                    interaction_matrix[user_id,chosen_item] = 1\n",
    "        # Calculate the average take-up rate\n",
    "        [avg_c_algo_1,avg_c_algo_2] = avg_take_up_rate_by_period(prev_consumed_items, user_assignments, params)\n",
    "        avg_c_algo_1_list.append(np.mean(avg_c_algo_1[params.initial_periods:]))\n",
    "        avg_c_algo_2_list.append(np.mean(avg_c_algo_2[params.initial_periods:]))\n",
    "        if b < params.B:\n",
    "            # Print the count of the simulation with replacement\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\", end='\\r', flush=True)\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "        else:\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\")\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "\n",
    "    # Calculate the average take up rate for algo_1 and algo_2 across simulations\n",
    "    avg_algo_1 = np.zeros(4)\n",
    "    avg_algo_1[0] = np.mean(avg_c_algo_1_list, axis=0)\n",
    "    avg_algo_1[1] = np.quantile(avg_c_algo_1_list,0.025)\n",
    "    avg_algo_1[2] = np.quantile(avg_c_algo_1_list,0.975)\n",
    "    avg_algo_1[3] = np.var(avg_algo_1, axis=0)\n",
    "    \n",
    "    avg_algo_2 = np.zeros(4)\n",
    "    avg_algo_2[0] = np.mean(avg_c_algo_2_list, axis=0)\n",
    "    avg_algo_2[1] = np.quantile(avg_c_algo_2_list,0.025)\n",
    "    avg_algo_2[2] = np.quantile(avg_c_algo_2_list,0.975)\n",
    "    avg_algo_2[3] = np.var(avg_c_algo_2_list, axis=0)\n",
    "    \n",
    "    # Calculate the average Treatment effect (algo_1 - algo_2) across simulations\n",
    "    avg_TE_list = np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list)\n",
    "    avg_TE = np.zeros(4)\n",
    "    avg_TE[0] = np.mean(avg_TE_list, axis=0)\n",
    "    avg_TE[1] = np.quantile(avg_TE_list,0.025)\n",
    "    avg_TE[2] = np.quantile(avg_TE_list,0.975)\n",
    "    avg_TE[3] = np.var(avg_TE_list, axis=0)\n",
    "    \n",
    "    # Calculate the average percentage Treatment effect across simulations\n",
    "    avg_pct_TE_list = (np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list))/np.array(avg_c_algo_1_list)\n",
    "    avg_pct_TE = np.zeros(4)\n",
    "    avg_pct_TE[0] = np.mean(avg_pct_TE_list, axis=0)\n",
    "    avg_pct_TE[1] = np.quantile(avg_pct_TE_list,0.025)\n",
    "    avg_pct_TE[2] = np.quantile(avg_pct_TE_list,0.975)\n",
    "    avg_pct_TE[3] = np.var(avg_pct_TE_list, axis=0)\n",
    "\n",
    "    return treatment_percentage, avg_algo_1, avg_algo_2, avg_TE, avg_pct_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb807d",
   "metadata": {},
   "source": [
    "#### Block 7: Clustering experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cdddee-1019-4d04-8192-c7f539b2c861",
   "metadata": {
    "id": "b8cdddee-1019-4d04-8192-c7f539b2c861",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def assign_clusters(preferences, max_clusters=10):\n",
    "    # List to store average silhouette scores for different numbers of clusters\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=0).fit(preferences)\n",
    "        silhouette_avg = silhouette_score(preferences, kmeans.labels_)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "    # Find the number of clusters that gives the highest silhouette score\n",
    "\n",
    "    optimal_clusters = np.argmax(silhouette_scores) + 2  # +2 because the range starts from 2\n",
    "    # Re-run KMeans with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=0).fit(preferences)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "\n",
    "    return cluster_assignments, optimal_clusters\n",
    "\n",
    "def run_simulation_cluster(params, preferences,user_item_utility, reserve_utilities, algo_1, algo_2, treatment_percentage, cluster_shuffle_percent):\n",
    "    \"\"\"\n",
    "    Cluster Method: \n",
    "    User data is divided into clusters based on predefined criteria.\n",
    "    All users within a cluster are assigned the same recommendation algorithm.\n",
    "    Both algo_1 and algo_2 learn from and act on the same user data.\n",
    "    Users interact with the same pool of items.\n",
    "    \n",
    "    Args:\n",
    "        params: Contains the enviroment set up.\n",
    "        user_item_utility (function/array): A utility function or matrix providing user-utility values for items.\n",
    "        reserve_utilities (array): Reserve_utilities for users.\n",
    "        algo_1 (callable): The first recommendation algorithm; signature should match how it's called below.\n",
    "        algo_2 (callable): The second recommendation algorithm; signature should match how it's called below.\n",
    "        treatment_percentage (float): Percentage of treated user\n",
    "\n",
    "    Returns:\n",
    "        avg_c_algo_1 (np.array): [mean, 2.5% quantile, 97.5% quantile, variance] of take-up rates for algo_1.\n",
    "        avg_c_algo_2 (np.array): Same structure as avg_c_algo_1 but for algo_2.\n",
    "        avg_TE (np.array): Treatment effect (algo_1 - algo_2) summary stats.\n",
    "        avg_pct_TE (np.array): Percentage-based treatment effect ((algo_1 - algo_2)/algo_1) summary stats.\n",
    "    \"\"\"\n",
    "    # Initialize results lists\n",
    "    avg_c_algo_1_list = []\n",
    "    avg_c_algo_2_list = []\n",
    "\n",
    "    # Pre-generate user assignment matrix\n",
    "    # Same assignment matrix for all sub-simulation\n",
    "    cluster_assignments, optimal_clusters = assign_clusters(preferences, max_clusters=10)\n",
    "    \n",
    "    ### Randomly reassigning cluster_shuffle_percent from each cluster\n",
    "    # Initiate the new assignments after shuffling\n",
    "    new_assignments = cluster_assignments.copy()\n",
    "    \n",
    "    if cluster_shuffle_percent > 0 and optimal_clusters > 1:\n",
    "        for cluster_id in range(optimal_clusters):\n",
    "            # Determine number of users to be shuffle for current cluster (n_shuffle_c)\n",
    "            cluster_users = np.where(cluster_assignments == cluster_id)[0]\n",
    "            n_cluster_users = len(cluster_users)\n",
    "            n_shuffle_c = int(cluster_shuffle_percent * n_cluster_users)\n",
    "            \n",
    "            if n_shuffle_c > 0:\n",
    "                # Randomly pick n_shuffle_c users to shuffle from this cluster\n",
    "                shuffle_indices = np.random.choice(cluster_users, size=n_shuffle_c, replace=False)\n",
    "                \n",
    "                # Assign each of these users to a different cluster\n",
    "                for idx in shuffle_indices:\n",
    "                    old_cluster = cluster_assignments[idx]\n",
    "                    # Exclude the old cluster from possible new clusters\n",
    "                    possible_new_clusters = [c for c in range(optimal_clusters) if c != old_cluster]\n",
    "                    # Update new user assignments\n",
    "                    new_assignments[idx] = np.random.choice(possible_new_clusters)\n",
    "    \n",
    "    # Replace old assignments with new cluster assignments             \n",
    "    cluster_assignments = new_assignments\n",
    "\n",
    "    # Number of new items in each period\n",
    "    n_new = params.num_items_per_period\n",
    "\n",
    "    # For each round of simulation\n",
    "    for b in range(params.B):\n",
    "\n",
    "        # Generate random noise for each period and user\n",
    "        # Shape: (num_periods x num_users x (num_periods * num_items_per_period))\n",
    "        noise = np.random.normal(0, 1,(params.num_periods,params.num_users, params.num_periods * params.num_items_per_period))\n",
    "        \n",
    "        # Initialize the user-item interaction matrix: 0 indicates no consumption, 1 indicates consumption\n",
    "        # It’s essentially the interaction history that the algorithms use to learn user preferences.\n",
    "        # Shape: (num_users x num_items)\n",
    "        interaction_matrix = np.zeros((params.num_users, params.num_items))\n",
    "\n",
    "        # Record previous consumption to keep track of all items consumed by each user after the initial period\n",
    "        # Used later to calculate take up rate\n",
    "        prev_consumed_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "        for t in range(params.num_periods):\n",
    "\n",
    "            #### Introduce new goods\n",
    "            # list(range(t * n_new, (t + 1) * n_new)) generates a list of new item indices introduced at period t. \n",
    "            # For example, if n_new = 5 and t = 2, this would produce [10, 11, 12, 13, 14].\n",
    "            # np.repeat(..., params.num_users, axis=0) replicates this list so that each user has the same set of new items to choose from initially.\n",
    "            new_items = np.repeat([list(range(t * n_new, (t + 1) * n_new))], params.num_users, axis=0)\n",
    "            \n",
    "            # np.apply_along_axis(np.random.shuffle, 1, new_items) shuffles the order of these new item indices independently for each user.\n",
    "            np.apply_along_axis(np.random.shuffle, 1, new_items)\n",
    "            \n",
    "            # Initialize recommended items list for each user\n",
    "            recommended_items = [[] for _ in range(params.num_users)]\n",
    "\n",
    "            if t == params.initial_periods-1:\n",
    "\n",
    "                # Randomly assign half the clusters to treatment based on the treatment percentage\n",
    "                num_treatment_clusters = int(np.floor(optimal_clusters * treatment_percentage))\n",
    "                treatment_clusters = np.random.choice(np.arange(optimal_clusters), size=num_treatment_clusters, replace=False)\n",
    "                \n",
    "                # Assign users to treatment based on their cluster membership\n",
    "                # Since clusters vary in size, the actual percentage of users assigned to treatment may differ from the specified treatment_percentage.\n",
    "                user_assignments = np.isin(cluster_assignments, treatment_clusters)\n",
    "\n",
    "                # Calculate the actual percentage of users assigned to treatment\n",
    "                actual_treatment_percentage = np.sum(user_assignments) / len(user_assignments)\n",
    "                \n",
    "            #### Recommendation step (happens only after initial periods)\n",
    "            # Update the training data every training_frequency periods:\n",
    "            if t % params.training_frequency == 0 and t >= params.initial_periods:\n",
    "                # Use item interation data for each user up to the current period (t * n_new) as training data\n",
    "                # :(t * n_new) reflects all the items introduced up to the start of period t\n",
    "                training_data = interaction_matrix[:, :(t * n_new)]\n",
    "                \n",
    "                # Recommended_items: Matrix of ranked item IDs recommended to each user.\n",
    "                recommended_items_1 = algo_1(training_data, noise[t,:, :(t * n_new)])\n",
    "                recommended_items_2 = algo_2(training_data, noise[t,:, :(t * n_new)])\n",
    "\n",
    "                # Merge the two algorithms' recommendation list\n",
    "                recommended_items = recommended_items_1.copy()\n",
    "                recommended_items[user_assignments] = recommended_items_2[user_assignments]\n",
    "\n",
    "            #### Consumption step\n",
    "            # Simulate user consumption\n",
    "            # chosen_items reflects ID of the item each user chooses to consume, \n",
    "            # where -1 indicates that user does not consume any item\n",
    "            if t <  params.initial_periods:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "            else:\n",
    "                chosen_items = consume_item_all_users_loop(recommended_items, new_items, user_item_utility, reserve_utilities, params)\n",
    "\n",
    "            # Update the user-item interaction in interaction_matrix and prev_consumed_items\n",
    "            for user_id, chosen_item in enumerate(chosen_items):\n",
    "                prev_consumed_items[user_id].append(chosen_item)\n",
    "                if chosen_item != -1:\n",
    "                    interaction_matrix[user_id,chosen_item] = 1\n",
    "            \n",
    "        # Calculate the average take-up rate\n",
    "        [avg_c_algo_1,avg_c_algo_2] = avg_take_up_rate_by_period(prev_consumed_items, user_assignments, params)\n",
    "        avg_c_algo_1_list.append(np.mean(avg_c_algo_1[params.initial_periods:]))\n",
    "        avg_c_algo_2_list.append(np.mean(avg_c_algo_2[params.initial_periods:]))\n",
    "        if b < params.B:\n",
    "            # Print the count of the simulation with replacement\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\", end='\\r', flush=True)\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "        else:\n",
    "            print(f\"Simulation {b + 1} of {params.B} completed\")\n",
    "            with open(params.output_file, 'a') as f:\n",
    "                f.write(f\"Simulation {b + 1} of {params.B} completed\\n\")\n",
    "    \n",
    "    # Calculate the average take up rate for algo_1 and algo_2 across simulations\n",
    "    avg_algo_1 = np.zeros(4)\n",
    "    avg_algo_1[0] = np.mean(avg_c_algo_1_list, axis=0)\n",
    "    avg_algo_1[1] = np.quantile(avg_c_algo_1_list,0.025)\n",
    "    avg_algo_1[2] = np.quantile(avg_c_algo_1_list,0.975)\n",
    "    avg_algo_1[3] = np.var(avg_algo_1, axis=0)\n",
    "    \n",
    "    avg_algo_2 = np.zeros(4)\n",
    "    avg_algo_2[0] = np.mean(avg_c_algo_2_list, axis=0)\n",
    "    avg_algo_2[1] = np.quantile(avg_c_algo_2_list,0.025)\n",
    "    avg_algo_2[2] = np.quantile(avg_c_algo_2_list,0.975)\n",
    "    avg_algo_2[3] = np.var(avg_algo_2, axis=0)\n",
    "    \n",
    "    # Calculate the average Treatment effect (algo_1 - algo_2) across simulations\n",
    "    avg_TE_list = np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list)\n",
    "    avg_TE = np.zeros(4)\n",
    "    avg_TE[0] = np.mean(avg_TE_list, axis=0)\n",
    "    avg_TE[1] = np.quantile(avg_TE_list,0.025)\n",
    "    avg_TE[2] = np.quantile(avg_TE_list,0.975)\n",
    "    avg_TE[3] = np.var(avg_TE, axis=0)\n",
    "    \n",
    "    # Calculate the average percentage Treatment effect across simulations\n",
    "    avg_pct_TE_list = (np.array(avg_c_algo_1_list)-np.array(avg_c_algo_2_list))/np.array(avg_c_algo_1_list)\n",
    "    avg_pct_TE = np.zeros(4)\n",
    "    avg_pct_TE[0] = np.mean(avg_pct_TE_list, axis=0)\n",
    "    avg_pct_TE[1] = np.quantile(avg_pct_TE_list,0.025)\n",
    "    avg_pct_TE[2] = np.quantile(avg_pct_TE_list,0.975)\n",
    "    avg_pct_TE[3] = np.var(avg_pct_TE_list, axis=0)\n",
    "\n",
    "    return actual_treatment_percentage, avg_algo_1, avg_algo_2, avg_TE, avg_pct_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391b354-c463-435b-abec-1cd6982d4bde",
   "metadata": {
    "id": "a391b354-c463-435b-abec-1cd6982d4bde",
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Block 8: Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc061f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    ###########\n",
    "    n_sim = 1000\n",
    "    ###########\n",
    "    params = Param(K=10, num_periods=100, num_users=100, num_items=1000,\n",
    "                   sigma=1e-5, B=n_sim, random_seed=np.arange(30), per=50,\n",
    "                   output_file=\"output.txt\")\n",
    "    num_items_per_period = int(params.num_items / params.num_periods)\n",
    "    params.num_items_per_period = num_items_per_period\n",
    "    params.training_frequency = 1\n",
    "    params.initial_periods = 10\n",
    "    params.gamma_pref = float(os.getenv('GAMMA_PREF', '1'))\n",
    "    params.gamma_item = float(os.getenv('GAMMA_ITEM', '1'))\n",
    "    params.pref_group = False\n",
    "    treatment_percentage = float(os.getenv(\"TREATMENT_PERCENT\", \"0.5\"))\n",
    "    cluster_shuffle_percentage = float(os.getenv(\"CLUSTER_SHUFFLE_PERCENTAGE\", \"0.0\"))\n",
    "\n",
    "    seed = 13034\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    cluster_size = int(os.getenv(\"CLUSTER_SIZE\", \"10\"))\n",
    "\n",
    "    # Generate primitives\n",
    "    preferences = generate_user_preferences_cluster_with_size(params, cluster_size)\n",
    "    characteristics = generate_item_char_cluster(params)\n",
    "    user_item_utility = generate_values(characteristics, preferences, params)\n",
    "    reserve_utility = calculate_reserve_utilities(user_item_utility, params)\n",
    "\n",
    "    # Define algorithms using a dictionary\n",
    "    algorithms = {\n",
    "        \"Item\": Item_based_CF,\n",
    "        \"User\": User_based_CF,\n",
    "        \"Random\": Random_alg,\n",
    "        \"Ideal\": lambda training_data, noise: Ideal_alg(\n",
    "            training_data, user_item_utility, noise\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Define method functions using a dictionary\n",
    "    method_functions = {\n",
    "        \"Naive\": run_simulation_naive,\n",
    "        \"Data-diverted\": run_simulation_data_diverted, \n",
    "        \"Cluster\": run_simulation_cluster,\n",
    "        \"User-corpus\": run_simulation_user_corpus_codiverted\n",
    "    }\n",
    "\n",
    "    # Methods and combinations\n",
    "    methods = [\"Naive\", \"Data-diverted\", \"Cluster\", \"User-corpus\"]\n",
    "    combinations = [\n",
    "        (\"Item\", \"Ideal\"),\n",
    "        (\"Item\", \"Random\"),\n",
    "        (\"Item\", \"User\"),\n",
    "        (\"Ideal\", \"Item\"),\n",
    "        (\"Ideal\", \"Random\"),\n",
    "        (\"Ideal\", \"User\"),\n",
    "        (\"Random\", \"Item\"),\n",
    "        (\"Random\", \"Ideal\"),\n",
    "        (\"Random\", \"User\"),\n",
    "        (\"User\", \"Ideal\"),\n",
    "        (\"User\", \"Random\"),\n",
    "        (\"User\", \"Item\"),\n",
    "    ]\n",
    "    algo_list = [\"Item\", \"User\", \"Random\", \"Ideal\"]\n",
    "\n",
    "    # Results storage\n",
    "    results = []\n",
    "    file_path = f\"./results/Simulation_result.csv\"\n",
    "\n",
    "    # Reference simulations\n",
    "    for algo_name in algo_list:\n",
    "        alg = algorithms.get(algo_name)\n",
    "        TUR, TUR_2, TE, pct_TE = run_simulation_ref(\n",
    "            params, user_item_utility, reserve_utility, alg, alg\n",
    "        )\n",
    "        add_result(\n",
    "            results,\n",
    "            algo_name,\n",
    "            algo_name,\n",
    "            \"Ref\",\n",
    "            params.gamma_pref,\n",
    "            0,\n",
    "            cluster_shuffle_percentage,\n",
    "            TUR,\n",
    "            TUR_2,\n",
    "            TE,\n",
    "            pct_TE\n",
    "        )\n",
    "\n",
    "    # Other methods\n",
    "    for method in methods:\n",
    "        method_function = method_functions.get(method)\n",
    "        for algo1_name, algo2_name in combinations:\n",
    "            algo1 = algorithms.get(algo1_name)\n",
    "            algo2 = algorithms.get(algo2_name)\n",
    "\n",
    "            # Determine if 'preferences' is needed\n",
    "            if method == \"Cluster\":\n",
    "                TP, TUR1, TUR2, TE, pct_TE = method_function(\n",
    "                    params,\n",
    "                    preferences,\n",
    "                    user_item_utility,\n",
    "                    reserve_utility,\n",
    "                    algo1,\n",
    "                    algo2,\n",
    "                    treatment_percentage,\n",
    "                    cluster_shuffle_percentage,\n",
    "                )\n",
    "            else:\n",
    "                TP, TUR1, TUR2, TE, pct_TE = method_function(\n",
    "                    params,\n",
    "                    user_item_utility,\n",
    "                    reserve_utility,\n",
    "                    algo1,\n",
    "                    algo2,\n",
    "                    treatment_percentage,\n",
    "                )\n",
    "\n",
    "            add_result(\n",
    "                results,\n",
    "                algo1_name,\n",
    "                algo2_name,\n",
    "                method,\n",
    "                params.gamma_pref,\n",
    "                TP,\n",
    "                cluster_shuffle_percentage,\n",
    "                TUR1,\n",
    "                TUR2,\n",
    "                TE,\n",
    "                pct_TE,\n",
    "            )\n",
    "\n",
    "    # Save or append results to CSV\n",
    "    add_and_save_results(results, file_path)\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "def add_and_save_results(results, file_path):\n",
    "    # Check if the CSV file already exists\n",
    "    file_exists = os.path.exists(file_path)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Append to the CSV file without writing the header if the file already exists\n",
    "    results_df.to_csv(file_path, mode='a', header=not file_exists, index=False)\n",
    "\n",
    "def add_result(results, algo1, algo2, method, gamma_pref, treatment_percentage, cluster_shuffle_percentage, TUR_algo_1, TUR_algo_2, TE, pct_TE):\n",
    "    results.append({\n",
    "        \"algo1\": algo1,\n",
    "        \"algo2\": algo2,\n",
    "        \"method\": method,\n",
    "        \"gamma_pref\": gamma_pref,\n",
    "        \"treatment_percentage\": treatment_percentage,\n",
    "        \"cluster_shuffle_percentage\": cluster_shuffle_percentage,\n",
    "        \"TUR_algo_1\": TUR_algo_1,\n",
    "        \"TUR_algo_2\": TUR_algo_2,\n",
    "        \"TE\": TE,\n",
    "        \"Percentage_TE\": pct_TE\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26933c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdab20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
